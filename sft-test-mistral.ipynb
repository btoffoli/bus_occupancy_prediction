{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "006f15ac",
   "metadata": {},
   "source": [
    "Importando bibliotecas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511bc102",
   "metadata": {},
   "source": [
    "Iniciando modelo TinyLlama-1.1B-Chat-v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e95f542d-173e-4575-a23a-4df666e96f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fine_tune:self.model_name: unsloth/mistral-7b-v0.3-bnb-4bit\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /unsloth/mistral-7b-v0.3-bnb-4bit/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "/home/btoffoli/projects/ufes/gpt/bus_occupancy_prediction/.venv/lib/python3.13/site-packages/transformers/quantizers/auto.py:207: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
      "  warnings.warn(warning_msg)\n",
      "DEBUG:bitsandbytes.cextension:Loading bitsandbytes native library from: /home/btoffoli/projects/ufes/gpt/bus_occupancy_prediction/.venv/lib/python3.13/site-packages/bitsandbytes/libbitsandbytes_cuda124.so\n",
      "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /unsloth/mistral-7b-v0.3-bnb-4bit/resolve/main/generation_config.json HTTP/1.1\" 200 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /unsloth/mistral-7b-v0.3-bnb-4bit/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "DEBUG:fine_tune:Reading datasets in batches: data_converted_txt\n",
      "DEBUG:fine_tune:filenames: ['occupancy-events-20240107.converted.txt', 'occupancy-events-20240108.converted.txt', 'occupancy-events-20240109.converted.txt', 'occupancy-events-20240301.converted.txt', 'occupancy-events-20240302.converted.txt', 'occupancy-events-20240303.converted.txt', 'occupancy-events-20240501.converted.txt', 'occupancy-events-20240502.converted.txt', 'occupancy-events-20240701.converted.txt']\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /unsloth/mistral-7b-v0.3-bnb-4bit/resolve/main/config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,815,744 || all params: 7,254,839,296 || trainable%: 0.0939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /unsloth/mistral-7b-v0.3-bnb-4bit/resolve/main/config.json HTTP/1.1\" 200 0\n"
     ]
    }
   ],
   "source": [
    "from fine_tune import BusOccupancyFineTune, convert_to_text\n",
    "\n",
    "boft_model = BusOccupancyFineTune(\n",
    "  mode='fine_tune',\n",
    "  model_name='unsloth/mistral-7b-v0.3-bnb-4bit',\n",
    "  datasets_path='data_converted_txt',  \n",
    ")\n",
    "\n",
    "\n",
    "boft_model.train()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e600e1fc",
   "metadata": {},
   "source": [
    "Trying to make prediction with the model still in memory that was just trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2143e37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "  {\"occupancyLevel\":0,\"timestamp\":\"2024-03-03T03:17:09.000Z\",\"tripId\":84514167,\"tripScheduledTime\":\"2024-03-03T03:01:00.000Z\",\"tripStartTime\":\"2024-03-03T03:04:10.000Z\",\"tripEndTime\":\"2024-03-03T03:58:36.000Z\",\"busStopLocation\":4711,\"routeTotalLength\":21027,\"busStopId\":1446,\"tripRouteId\":1865,\"weatherTemperature\":24.2,\"weatherPrecipitation\":0},\n",
    "  {\"occupancyLevel\":1,\"timestamp\":\"2024-03-03T03:09:31.000Z\",\"tripId\":84514167,\"tripScheduledTime\":\"2024-03-03T03:01:00.000Z\",\"tripStartTime\":\"2024-03-03T03:04:10.000Z\",\"tripEndTime\":\"2024-03-03T03:58:36.000Z\",\"busStopLocation\":2965,\"routeTotalLength\":21027,\"busStopId\":185,\"tripRouteId\":1865,\"weatherTemperature\":24.2,\"weatherPrecipitation\":0},\n",
    "  {\"occupancyLevel\":2,\"timestamp\":\"2024-03-03T04:21:50.000Z\",\"tripId\":84513157,\"tripScheduledTime\":\"2024-03-03T03:50:00.000Z\",\"tripStartTime\":\"2024-03-03T03:54:01.000Z\",\"tripEndTime\":\"2024-03-03T04:58:23.000Z\",\"busStopLocation\":11716,\"routeTotalLength\":27426,\"busStopId\":755,\"tripRouteId\":4040,\"weatherTemperature\":23.4,\"weatherPrecipitation\":0}\n",
    "]\n",
    "\n",
    "for i in questions:\n",
    "  q = convert_to_text(i).strip()\n",
    "  question = q[:-1]\n",
    "  print(question)\n",
    "  right_resp = q[-1]\n",
    "  resp = boft_model.predict(question)\n",
    "  print(f\"**** resp was {resp}\")\n",
    "  print(f\"**** but correct would be {q}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
